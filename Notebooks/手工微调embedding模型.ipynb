{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "微调embedding模型以便增强RAG整体的检索能力"
      ],
      "metadata": {
        "id": "x07kjz1j-uUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 微调Embedding和微调LLM的关系"
      ],
      "metadata": {
        "id": "sdMuxMsO_GgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 相似点\n",
        "\n",
        "  两种类型的微调都遵循相同的方法，即生成用于训练和评估的数据集，微调模型，最后评估基本模型和微调模型之间的性能。\n",
        "  使用LLM自动生成训练和评估数据集。\n",
        "\n",
        "- 不同点\n",
        "\n",
        "  数据集内容在LLM微调和Embedding模型微调之间有所不同。用于LLM微调的数据集包含LLM生成的问题。在微调过程中，包括问题、答案、系统prompt等在内的一系列数据将以JSON行( jsonl)文件的形式传递给要进行微调的模型。\n",
        "  不同的是，用于Embedding模型微调的数据集包含以下三组:\n",
        "\n",
        "  - `queries`：node_id映射和LLM生成的问题的集合。\n",
        "  - `corpus`：node_id映射和相应节点中的文本的集合。\n",
        "  - `relevant_docs`：查询的node_id和语料库 node_id之间的交叉引用映射的集合。给定一个查询，它告诉Embedding模型要查找哪个文本节点/语料库。"
      ],
      "metadata": {
        "id": "zS1GLaGL_ni1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 微调Embedding的具体步骤"
      ],
      "metadata": {
        "id": "VPW7bPdUBGsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "主要任务包括:\n",
        "\n",
        "1. 通过调用 `EmbeddingQAFinetuneDataset`函数`generate_qa_embedding_pairs`，自动生成评估和训练数据集的数据。\n",
        "2. 通过传入基本模型和训练数据集来构造`SentenceTransformersFinetuneEngine`，然后调用其`finetune`函数来训练基本模型。\n",
        "3. 创建经过微调的模型。\n",
        "4. 调用向量存储索引检索器检索相关节点并评估基本模型的命中率。\n",
        "5. 调用`InformationRetrievalEvaluator`来评估基本模型。\n",
        "6. 调用向量存储索引检索器检索相关节点并评估微调模型的命中率。\n",
        "7. 调用InformationRetrievalEvaluator来评估经过微调的模型。"
      ],
      "metadata": {
        "id": "ewvJlkuA_pTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: 生成数据集"
      ],
      "metadata": {
        "id": "00BRst_JBMvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用LLM来自动生成训练和评估的数据集。"
      ],
      "metadata": {
        "id": "Zjivu9ohBRjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 下载数据集\n",
        "!curl https://d18rn0p25nwr6d.cloudfront.net/CIK-0001045810/4e9abe7b-fdc7-4cd2-8487-dc3a99f30e98.pdf --output nvidia-sec-10k-2022.pdf"
      ],
      "metadata": {
        "id": "HX8Y233vBW-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_corpus(docs, for_training=False, verbose=False):\n",
        "    parser = SimpleNodeParser.from_defaults()\n",
        "    if for_training:\n",
        "        nodes = parser.get_nodes_from_documents(docs[:90], show_progress=verbose)\n",
        "    else:\n",
        "        nodes = parser.get_nodes_from_documents(docs[91:], show_progress=verbose)\n",
        "\n",
        "    if verbose:\n",
        "        print(f'Parsed {len(nodes)} nodes')\n",
        "\n",
        "    return nodes\n",
        "\n",
        "SEC_FILE = ['nvidia-sec-10k-2022.pdf']\n",
        "\n",
        "print(f\"Loading files {SEC_FILE}\")\n",
        "\n",
        "reader = SimpleDirectoryReader(input_files=SEC_FILE)\n",
        "docs = reader.load_data()\n",
        "print(f'Loaded {len(docs)} docs')\n",
        "\n",
        "train_nodes = load_corpus(docs, for_training=True, verbose=True)\n",
        "val_nodes = load_corpus(docs, for_training=False, verbose=True)\n"
      ],
      "metadata": {
        "id": "mdfDvkGKBZ56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成合成查询和数据集\n",
        "from llama_index.finetuning import (\n",
        "    generate_qa_embedding_pairs,\n",
        "    EmbeddingQAFinetuneDataset,\n",
        ")\n",
        "from llama_index.llms import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')# os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "train_dataset = generate_qa_embedding_pairs(train_nodes)\n",
        "val_dataset = generate_qa_embedding_pairs(val_nodes)\n",
        "\n",
        "train_dataset.save_json(\"train_dataset.json\")\n",
        "val_dataset.save_json(\"val_dataset.json\")\n",
        "\n",
        "train_dataset = EmbeddingQAFinetuneDataset.from_json(\"train_dataset.json\")\n",
        "val_dataset = EmbeddingQAFinetuneDataset.from_json(\"val_dataset.json\")"
      ],
      "metadata": {
        "id": "wsDcRkyaBjja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: 微调Embedding模型"
      ],
      "metadata": {
        "id": "uWue2tvVB84K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`SentenceTransformersFinetuneEngine`就是为这个任务设计的。在底层，它执行多个子任务:\n",
        "\n",
        "- 通过构建SentenceTransformer加载预训练模型，传入BAAI/big-small-en模型id。\n",
        "- 定义数据加载器。它加载我们的训练数据集，将其解析为查询，语料库和relevant_docs。然后循环查询，将relevant_docs中的node_id与corpus中的文本节点进行映射，构造InputExample，其列表依次传递到创建DataLoader中.\n",
        "- 定义loss（损失函数）。它使用sentence_transformers multiplenegativerankingloss来训练检索设置的Embeddings。\n",
        "- 定义评估器。它设置了一个带有eval数据集的评估器来监控Embedding模型在训练期间的表现。\n",
        "- 运行训练。它插入上面定义的数据加载器、损失函数和评估器来运行训练。\n",
        "\n",
        "LlamaIndex将微调Embedding模型的所有详细子任务封装在一个`SentenceTransformersFinetuneEngine`中，我们所需要做的就是调用它的`finetune`函数"
      ],
      "metadata": {
        "id": "KoxpY4M8CJLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.finetuning import SentenceTransformersFinetuneEngine\n",
        "\n",
        "finetune_engine = SentenceTransformersFinetuneEngine(\n",
        "    train_dataset,\n",
        "    model_id=\"BAAI/bge-small-en\",\n",
        "    model_output_path=\"test_model\",\n",
        "    val_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "finetune_engine.finetune()\n",
        "\n",
        "embed_model = finetune_engine.get_finetuned_model()"
      ],
      "metadata": {
        "id": "CLKotXUUCcn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: 评估微调后的模型"
      ],
      "metadata": {
        "id": "AZFMfV1SCfTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们使用两种不同的评估方法:\n",
        "\n",
        "- 命中率:对每个query / relevant_doc对进行简单的top-k检索。如果搜索结果包含relevant_doc，那么它就是一个“命中”。这可以用于专有的Embeddings，例如OpenAI的Embedding模型和开源Embedding模型。请参阅下面代码片段中的evaluate函数。\n",
        "\n",
        "- `InformationRetrievalEvaluator`:一个更全面的用于评估开源Embeddings的度量套件。请参阅下面代码片段中的evaluate_st函数。"
      ],
      "metadata": {
        "id": "bngffK3GCjEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings import OpenAIEmbedding\n",
        "from llama_index import ServiceContext, VectorStoreIndex\n",
        "from llama_index.schema import TextNode\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# function for hit rate evals\n",
        "def evaluate(\n",
        "    dataset,\n",
        "    embed_model,\n",
        "    top_k=5,\n",
        "    verbose=False,\n",
        "):\n",
        "    corpus = dataset.corpus\n",
        "    queries = dataset.queries\n",
        "    relevant_docs = dataset.relevant_docs\n",
        "\n",
        "    service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
        "    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n",
        "    index = VectorStoreIndex(nodes, service_context=service_context, show_progress=True)\n",
        "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
        "\n",
        "    eval_results = []\n",
        "    for query_id, query in tqdm(queries.items()):\n",
        "        retrieved_nodes = retriever.retrieve(query)\n",
        "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
        "        expected_id = relevant_docs[query_id][0]\n",
        "        is_hit = expected_id in retrieved_ids  # assume 1 relevant doc\n",
        "\n",
        "        eval_result = {\n",
        "            \"is_hit\": is_hit,\n",
        "            \"retrieved\": retrieved_ids,\n",
        "            \"expected\": expected_id,\n",
        "            \"query\": query_id,\n",
        "        }\n",
        "        eval_results.append(eval_result)\n",
        "    return eval_results\n",
        "\n",
        "\n",
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def evaluate_st(\n",
        "    dataset,\n",
        "    model_id,\n",
        "    name,\n",
        "):\n",
        "    corpus = dataset.corpus\n",
        "    queries = dataset.queries\n",
        "    relevant_docs = dataset.relevant_docs\n",
        "\n",
        "    evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs, name=name)\n",
        "    model = SentenceTransformer(model_id)\n",
        "    return evaluator(model, output_path=\"results/\")"
      ],
      "metadata": {
        "id": "4rL-Jxm-CqL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eval OpenAI vs. Base Embedding vs. FineTuned Embedding"
      ],
      "metadata": {
        "id": "FiwZiSnKDKKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ada = OpenAIEmbedding()\n",
        "ada_val_results = evaluate(val_dataset, ada)\n",
        "\n",
        "df_ada = pd.DataFrame(ada_val_results)\n",
        "\n",
        "hit_rate_ada = df_ada['is_hit'].mean()"
      ],
      "metadata": {
        "id": "rU9qrBtDDYvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bge = \"local:BAAI/bge-small-en\"\n",
        "bge_val_results = evaluate(val_dataset, bge)\n",
        "\n",
        "df_bge = pd.DataFrame(bge_val_results)\n",
        "\n",
        "hit_rate_bge = df_bge['is_hit'].mean()\n",
        "\n",
        "evaluate_st(val_dataset, \"BAAI/bge-small-en\", name='bge')"
      ],
      "metadata": {
        "id": "HEheCSGJDb9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned = \"local:test_model\"\n",
        "val_results_finetuned = evaluate(val_dataset, finetuned)\n",
        "\n",
        "df_finetuned = pd.DataFrame(val_results_finetuned)\n",
        "\n",
        "hit_rate_finetuned = df_finetuned['is_hit'].mean()\n",
        "\n",
        "evaluate_st(val_dataset, \"test_model\", name='finetuned')"
      ],
      "metadata": {
        "id": "buAFiCpoDneE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}